{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ArcGIS API for Python: Assess burn scars after wildfires with ArcGIS Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll use ArcGIS API for Python to identify burn scars after two wildfires in Glacier National Park in Montana. You'll select satellite images before and after two wildfires, apply the normalized burn ratio (NBR) index to each image, and compute the difference to visualize the burn scars. You'll also learn about the short-wave infrared with dynamic range adjustment (DRA) rendering, how to symbolize a raster with a color ramp, and how to create your own area of interest polygon. \n",
    "\n",
    "**Note:** This is the second notebook in the [Analyze imagery with ArcGIS Notebooks](https://learn.arcgis.com/en/paths/analyze-imagery-with-arcgis-notebooks/) learning path. For an optimal experience, consider doing all four notebooks in the order proposed.\n",
    "\n",
    "This notebook was last tested on December 3, 2024.\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Set up the environment](#environment)\n",
    "* [Get the data](#data)\n",
    "* [Visualize and explore the imagery](#visualize)\n",
    "* [Perform the analysis](#analysis)\n",
    "* [Summary](#summary)\n",
    "* [Stretch goal](#stretch)\n",
    "* [Acknowledgments](#acknowledgments)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the summer of 2015, wildfires raged through Glacier National Park in Montana. Following fires such as these, it is critical for forest management services to measure the burn scars, as they will serve as a baseline to monitor forest regeneration. As the imagery analyst, you'll use Landsat satellite images from before and after the fires to identify the burn scars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment <a class=\"anchor\" id=\"environment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to import the Python modules and functions that you'll use in this notebook and that are not part of Python's default installation. Importing objects and functions makes them available for your code.\n",
    "\n",
    "1. Run the cell below to import the required objects and function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GIS from the arcgis package - this will allow you to create a GIS object to connect to ArcGIS Online.\n",
    "from arcgis import GIS\n",
    "\n",
    "# Import the ImageryLayer class from the arcgis.raster module so you can create imagery layer objects.\n",
    "from arcgis.raster import ImageryLayer\n",
    "\n",
    "# Import the apply, clip, nbr, and stretch functions from arcgis.raster.functions so you can apply\n",
    "# them to the imagery layers.\n",
    "from arcgis.raster.functions import apply, clip, nbr, stretch\n",
    "\n",
    "# Import the polygon class from arcgis.geometry so you can make polygon objects.\n",
    "from arcgis.geometry import Polygon\n",
    "\n",
    "# Import the within function from arcgis.geometry.filters so you can filter by the polygon geometry.\n",
    "from arcgis.geometry.filters import within\n",
    "\n",
    "# Import the datetime module so you can create datetime objects to filter imagery by date.\n",
    "import datetime as dt\n",
    "\n",
    "# Import the HBox widget from the ipywidgets module so you can compare two maps arranged horizontally beside each other.\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** If your notebook remains idle too long at any point in this workflow, it might time out. If that happens or any step takes longer than a couple of minutes to run, you should restart the kernel: on the Notebook's ribbon, click **Kernel** and **Restart**. Then run the cells again from the beginning of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll create an anonymous connection to ArcGIS Online.  \n",
    "\n",
    "2. Run the cell below to create the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variable gis to hold an anonymous connection to ArcGIS Online.\n",
    "gis = GIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an imagery layer instance\n",
    "\n",
    "You will use Landsat satellite imagery. You'll create an **ImageryLayer** instance from the [Multispectral Landsat image service](https://www.arcgis.com/home/item.html?id=d9b466d6a9e647ce8d1dd5fe12eb434b), hosted in [ArcGIS Living Atlas of the World](https://livingatlas.arcgis.com/en/home/).\n",
    "\n",
    "3. Run the cell below to create the imagery layer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called landsat_imagery that is an ImageryLayer object, \n",
    "# getting its images from the online Multispectral Landsat image service.\n",
    "landsat_imagery = ImageryLayer(\"https://landsat2.arcgis.com/arcgis/rest/services/Landsat/MS/ImageServer\")\n",
    "\n",
    "# Draw the imagery layer.\n",
    "landsat_imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your area of interest\n",
    "\n",
    "Next, to focus the workflow on the right location, you'll define your area of interest (AOI) in the part of Glacier National Park where the fires took place.  \n",
    "\n",
    "The AOI will be a rectangular [polygon](https://developers.arcgis.com/python/guide/part2-working-with-geometries/#Creating-Polygon-objects) defined by coordinates in the [WGS84 coordinate system](https://developers.arcgis.com/documentation/spatial-references/#4326---gps).\n",
    "\n",
    "4. Run the cell below to create a polygon object from a list of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polygon object from a list of five coordinates (expressed as five longitude and latitude pairs)\n",
    "# representing the polygon's corners. The last one is at the same location as the first to close \n",
    "# the polygon.\n",
    "wild_fires_aoi = Polygon({\"rings\": [[[-113.77754932351269,48.751093840355502],\n",
    "                                 [-113.77754932351269,48.489177416955975],\n",
    "                                 [-113.32190203534647,48.489177416955975],\n",
    "                                 [-113.32190203534647,48.751093840355502],\n",
    "                                 [-113.77754932351269,48.751093840355502]]],\n",
    "                       \"spatialReference\": {'wkid': 4326}})\n",
    "\n",
    "# The spatial reference of the polygon is set using the well-known ID or \"wkid\" code of 4326, \n",
    "# which corresponds to WGS84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the cell below to view the polygon in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called map that is an instance of the gis.map class.\n",
    "map1 = gis.map()\n",
    "\n",
    "# Draw the wild_fires_aoi polygon object on the map.\n",
    "map1.content.draw(wild_fires_aoi)\n",
    "\n",
    "# Set the extent of the map to the envelope of the feature.\n",
    "map1.content.extent = dict(wild_fires_aoi.envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the map.\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AOI is located in Glacier National Park, which comprises more than 1 million acres, and is centered on the area where the two 2015 fires took place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select specific Landsat scenes\n",
    "\n",
    "Next, you need to select specific images (or scenes) captured shortly before and shortly after the two 2015 wildfires, as your goal is to compare the imagery and see what has changed. In both cases, you want to select a scene captured during the summer, when trees have leaves, to better contrast with burnt areas.\n",
    "\n",
    "First, you'll select the Landsat scene captured before the fires. Using the **filter_by** function, you'll find all the scenes in the Landsat service that contain the AOI and were captured during the leaf-on season of 2014.  \n",
    "\n",
    "6. Run the cell below to filter the Landsat scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called selected_before that contains all the scenes that were captured \n",
    "# in the desired time range and contain the AOI (that is, the AOI must be \"within\" the scenes).\n",
    "selected_before = landsat_imagery.filter_by(time=[dt.datetime(2014, 6, 1), dt.datetime(2014, 9, 15)], geometry=within(wild_fires_aoi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the **query** function, you'll order scenes selected by cloud cover and keep only the first one (that is, the one with the least cloud cover). You'll also specify the property fields that you want to display. \n",
    "\n",
    "The result will be a 1-record [spatial dataframe](https://developers.arcgis.com/python/guide/introduction-to-the-spatially-enabled-dataframe/) (**sdf**), a convenient object to store geospatial data. You'll display that record.\n",
    "\n",
    "**Note:** Imaging satellites orbit far beyond the Earth’s atmosphere, so if clouds are present, they will appear in the scene captured, and obscure the Earth’s surface. The percentage of the scene obscured by cloud cover is a metadata field stored with every dataset, and this field can be used as a filter to find the scene with the least amount of cloud cover in the targeted date range.\n",
    "\n",
    "7. Run the cell below to get the scene with the least cloud cover and to display it as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame showing the one record with the least cloud cover.\n",
    "df_before = selected_before.query(out_fields=\"AcquisitionDate, GroupName, CloudCover, DayOfYear\", \n",
    "                    order_by_fields=\"CloudCover\",\n",
    "                    result_record_count=1).sdf\n",
    "\n",
    "# Display the data frame.\n",
    "df_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the 6/1/2014 to 9/15/2014 time range, the scene captured on 9/5/2014 contains the least cloud cover (0.61%), which is essentially cloud-free.\n",
    "\n",
    "You'll put the scene selected in a variable, referring to it by its **OBJECTID** attribute. This will enable easy access to it in the rest of the notebook.  \n",
    "\n",
    "8. Run the cell below to create a variable containing the scene referenced by **OBJECTID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable containing the scene referenced by OBJECTID.\n",
    "selected_scene_before = landsat_imagery.filter_by(f\"OBJECTID={df_before.iloc[0]['OBJECTID']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify whether the extent of the image is appropriate, you'll display the image selected in its default rendering along with the AOI polygon.  \n",
    "\n",
    "9. Run the cell below to create a second map, add the layer and the AOI to it, and draw the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map object.\n",
    "map2 = gis.map()\n",
    "\n",
    "# Add the selected_before layer.\n",
    "map2.content.add(selected_scene_before)  \n",
    "\n",
    "# Add the AOI polygon to the map.\n",
    "map2.content.draw(wild_fires_aoi)\n",
    "\n",
    "# Set the extent of the map to the envelope of the AOI polygon.\n",
    "map2.content.extent = dict(wild_fires_aoi.envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the map.\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AOI polygon is displayed on top of the selected image.  \n",
    "\n",
    "**Tip:** If the polygon does not display on top of the image, try running the previous cell one more time.\n",
    "\n",
    "10. On the map, zoom out until you see the entire image. \n",
    "\n",
    "The scene contains the entire AOI, which means that the extent of the image is satisfactory. By default, the Multispectral Landsat image service you are using in this notebook is rendered with the Agriculture with DRA band combination (bands SWIR1, NIR, and Blue or 6,5,2), which displays vegetation in vivid green, bare earth in orange brown, water in bluish black, and snow in turquoise blue. DRA, which stands for dynamic range adjustment is a technique to improve the contrast of the image. With DRA, the contrast is adjusted based on the pixel values in the current display extent, instead of taking into account all the pixels in the entire raster dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same method, you'll select a Landsat scene captured just after the two 2015 fires. The Reynolds Creek fire was at its height around July 22 and the Thompson fire around Aug 12. So you'll choose the date range from 8/20/2015 to 9/15/2015, targeting again the leaf-on season only.\n",
    "\n",
    "11. Run the cell below to select the scene after the second fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called selected_after that contains all the scenes that were captured  \n",
    "# in the desired time range and contain the AOI.\n",
    "selected_after = landsat_imagery.filter_by(time=[dt.datetime(2015, 8, 20), dt.datetime(2015, 9, 15)],\n",
    "                               geometry=within(wild_fires_aoi))\n",
    "\n",
    "# Create a data frame showing the one record with the least cloud cover.\n",
    "df_after = selected_after.query(out_fields=\"AcquisitionDate, GroupName, CloudCover, DayOfYear\", \n",
    "                    order_by_fields=\"CloudCover\",\n",
    "                    result_record_count=1).sdf\n",
    "\n",
    "# Show the dataframe.\n",
    "df_after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new scene selected has a suitable **AcquisitionDate** value (08/23/2015) and a low **CloudCover** percentage (1.88 percent).  \n",
    "\n",
    "12. Run the cell below to create a variable containing the scene referenced by **OBJECTID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable containing the scene referenced by OBJECTID.\n",
    "selected_scene_after = landsat_imagery.filter_by(f\"OBJECTID={df_after.iloc[0]['OBJECTID']}\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the extent of the image is appropriate, you'll display the new image selected along with the AOI polygon.  \n",
    "\n",
    "13. Run the cell below to draw the scene on a new map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a map.\n",
    "map3 = gis.map()\n",
    "\n",
    "# Add the scene to the map.\n",
    "map3.content.add(selected_after)\n",
    "\n",
    "# Add the AOI polygon to the map.\n",
    "map3.content.draw(wild_fires_aoi)\n",
    "\n",
    "# Set the extent of the map to the AOI envelope\n",
    "map3.content.extent = dict(wild_fires_aoi.envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw the map.\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, the image selected contains the entire AOI.\n",
    "\n",
    "You now have acquired all the data you need. Next, you'll explore the imagery and identify the burn scars visually. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and explore the imagery <a class=\"anchor\" id=\"visualize\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the before and after-fire images\n",
    "\n",
    "First, you'll prepare the before and after-fire images and display them in maps for exploring.\n",
    "\n",
    "The two scenes are much larger than the AOI. You'll clip them to the shape of the AOI polygon, keeping only the part that interests you.\n",
    "\n",
    "14. Run the cell below to clip the two scenes using the AOI polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable, clipped_before, to store the result of clipping the before scene using the AOI.\n",
    "clipped_before = clip(selected_scene_before,\n",
    "                  geometry=wild_fires_aoi)\n",
    "\n",
    "# Make a variable, clipped_after, to store the result of clipping the after scene using the AOI.\n",
    "clipped_after = clip(selected_scene_after,\n",
    "                  geometry=wild_fires_aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the two images side by side in natural color\n",
    "\n",
    "You will now display the two clipped images in side-by-side maps. To do that, you'll define a [function](https://www.w3schools.com/python/python_functions.asp) named **side_by_side**. \n",
    "\n",
    "15. Run the cell below to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Python function to display two rasters side-by-side.\n",
    "# Function definitions start with the def keyword, followed by open parentheses that include any \n",
    "# parameters the function will take, followed by close parentheses, followed by a colon. \n",
    "# In this case, the side_by_side function will take two input rasters and an extent as parameters.\n",
    "\n",
    "def side_by_side(raster_1, raster_2, map_extent):\n",
    "    \"\"\" Method for displaying 2 rasters side by side \"\"\"\n",
    "    # The text above in triple quotes is a \"docstring\", explaining what the function does.\n",
    "    # The code block that makes up a function is indented four spaces after the first line.\n",
    "    \n",
    "    # Make a map.\n",
    "    map_1 = gis.map()\n",
    "    # Make a second map.\n",
    "    map_2 = gis.map()\n",
    "    \n",
    "    # Add the first input raster parameter to map 1.\n",
    "    map_1.content.add(raster_1)\n",
    "    # Add the second input raster parameter to map 2.\n",
    "    map_2.content.add(raster_2)\n",
    "    \n",
    "    # sync maps' navigation\n",
    "    map_1.sync_navigation(map_2)\n",
    "\n",
    "    # Create VBoxes for each map and label\n",
    "    box1 = VBox([Label(\"Before\"), map_1], layout=Layout(width='50%'))\n",
    "    box2 = VBox([Label(\"After\"), map_2], layout=Layout(width='50%'))\n",
    "\n",
    "    # Place the VBoxes side by side using an HBox\n",
    "    hbox = HBox([box1, box2])\n",
    "    \n",
    "    # Draw the widget with the two side-by-side maps.\n",
    "    return hbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes two images (or [rasters](https://pro.arcgis.com/en/pro-app/latest/help/data/imagery/introduction-to-raster-data.htm)) and a map extent. It creates two maps, adds the rasters to them, sets the extent for each one, synchronizes navigation between them, and displays them side by side.\n",
    "\n",
    "**Note:** Don't worry if you are not familiar with functions and do not fully understand that piece of code. You can think of **side_by_side** as a custom tool that you have just defined, and you will now be able to use it in the rest of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll use the **side_by_side** function to display the two clipped images. You'll choose the natural color rendering with dynamic range adjustment (DRA). That rendering combines the blue, green, and red bands (2, 3, and 4), which shows colors close to what the human eye would usually see. To set the rendering, you'll apply a built-in [raster function](https://pro.arcgis.com/en/pro-app/latest/help/analysis/raster-functions/raster-functions.htm) using the **apply** function from arcgis.raster.functions. \n",
    "\n",
    "**Note:** See more information on [all the built-in rendering options](https://developers.arcgis.com/python/guide/raster-analysis-advanced-concepts/#Apply-built-in-raster-functions) in the Apply built-in raster functions section.\n",
    "\n",
    "16. Run the cell below to apply the **Natural Color with DRA** raster function to the two images and display the results side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to hold the result of applying the 'Natural Color with DRA' raster function \n",
    "# to the before image.\n",
    "natural_color_before = apply(clipped_before, 'Natural Color with DRA')\n",
    "\n",
    "# Create a variable to hold the result of applying the 'Natural Color with DRA' raster function \n",
    "# to the after image.\n",
    "natural_color_after = apply(clipped_after, 'Natural Color with DRA')\n",
    "\n",
    "# Display the two images side-by-side in the notebook results.\n",
    "side_by_side(raster_1=natural_color_before,\n",
    "          raster_2=natural_color_after,\n",
    "          map_extent=dict(wild_fires_aoi.envelope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Zoom in and out and pan to explore the images. \n",
    "The two maps are linked, so changing the extent in one changes the extent in the other.\n",
    "\n",
    "Since the natural color rendering shows the imagery the way it would appear to the human eye, it can help you get oriented quickly to the content of the imagery. For instance, you can recognize snow on some of the mountain crests, a lake, and vegetation (in dark greenish tones). The terrain appears quite mountainous with many crests and valleys. One interesting thing to note on the south side of the after image is that there is still some smoke from the Thompson fire, which was still burning when this image was captured. However, with this rendering, the burn scars in the second image are rather difficult to identify.\n",
    "\n",
    "**Note:** For the purpose of this exploration, ignore the fact that the before image looks a bit darker than the after image, as this is not a relevant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the short-wave infrared rendering\n",
    "\n",
    "You'll now try another rendering, the short-wave infrared band combination with DRA, to see whether it allows you to visualize the burn scars better. That rendering combines the shortwave infrared 2, shortwave infrared 1, and red bands (7, 6, and 4). \n",
    "\n",
    "As a more compact way of writing the code, you don't need to create separate variables for the new rendering. Instead, you'll apply it directly in your **side_by_side** call.\n",
    "\n",
    "18. Run the cell below to display the two images side by side with the **Short-wave Infrared with DRA** raster function applied to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the side_by_side function on the first image with the 'Short-wave Infrared with DRA' \n",
    "# raster function applied to it, the second image with the 'Short-wave Infrared with DRA' \n",
    "# raster function applied to it, and the AOI extent.\n",
    "\n",
    "side_by_side(raster_1=apply(clipped_before, 'Short-wave Infrared with DRA'),\n",
    "          raster_2=apply(clipped_after, 'Short-wave Infrared with DRA'),\n",
    "          map_extent=dict(wild_fires_aoi.envelope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this rendering, the vegetation appears in bright green, the water in black tones, and the snow in bright blue. You can now identify the two burn scars in the after-fire image much more clearly, as they emerge clearly delineated in light brown tones. In the top half of the image, the Reynolds Creek fire scar appears just above the lake. The Thompson fire scar appears clearly at the bottom of the image. Notice that the short-wave infrared band combination allows for smoke penetration: you can see the Thompson fire scar instead of seeing the smoke. \n",
    "\n",
    "19. Zoom in and pan to observe the two burn scars in more detail.\n",
    "\n",
    "Using different band combinations allows the human eye to better see certain features and supports a more insightful interpretation of the imagery. However, this process simply changes the display; it does not generate new data. To go further, you'll perform change analysis on your imagery.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the analysis <a class=\"anchor\" id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the normalized burn ratio index\n",
    "\n",
    "You now want to identify the burn scars more formally. To do that, you will use a spectral index: normalized burn ratio (NBR). In contrast to the color combinations you have seen until now, a spectral index is a different way of using multispectral imagery.  It uses a mathematical calculation to compute a ratio between different bands for every pixel in an image. The result is a single-band raster that highlights a specific phenomenon. \n",
    "\n",
    "The NBR index is particularly appropriate to identify burned areas and provide a measure of burn severity. It involves the  near infrared (NIR) and shortwave infrared (SWIR) bands, which for this imagery are bands 5 and 7, respectively. The formula is as follows: \n",
    "\n",
    "`(NIR - SWIR) / (NIR + SWIR)` \n",
    "\n",
    "You'll apply the NBR index to the before- and after-fire images.\n",
    "\n",
    "20. Run the cell below to apply the NBR index to the images to produce two NBR rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an nbr_before variable to hold the result of applying the nbr function to the clipped_before \n",
    "# raster, using the 5 and 7 bands.\n",
    "nbr_before = nbr(clipped_before,\n",
    "                    band_indexes=\"5 7\")\n",
    "\n",
    "# Create an nbr_after variable to hold the result of applying the nbr function to the clipped_after \n",
    "# raster, using the 5 and 7 bands.\n",
    "nbr_after = nbr(clipped_after,\n",
    "                    band_indexes=\"5 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Run the cell below to display the two NBR rasters side by side.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the side_by_side function to display the two NBR rasters.\n",
    "side_by_side(raster_1=nbr_before,\n",
    "          raster_2=nbr_after,\n",
    "          map_extent=dict(wild_fires_aoi.envelope))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NBR rasters have values that vary from -1 to 1. Burnt or no vegetation pixels have a very low value and appear in black, and healthy vegetation pixels have a high value and appear in light gray. Water and snow have the highest values and appear in white. \n",
    "\n",
    "As you compare the two maps, you can see that the burned area changed from light gray to black, indicating the loss of vegetation. However, the burn scar may be difficult to isolate, since many bare earth patches are naturally devoid of vegetation and also appear in dark tones. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the difference between the NBR rasters\n",
    "\n",
    "Next, you'll compute the difference between the two NBR rasters to identify where the pixels have changed from not burnt to burnt. For every pixel, the value of the **after_nbr** raster will be [subtracted](https://pro.arcgis.com/en/pro-app/2.8/arcpy/spatial-analyst/arithmetic-minus-operator.htm) from the value of the **before_nbr** raster. The resulting output raster will highlight the pixels where there was a sharp drop in NBR value, which corresponds to the burn scars. Bare earth pixels, which have low NBR values before and after the fires, will get a value of 0 or close to zero.\n",
    "\n",
    "22. Run the cell below to compute the difference between the rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a change_in_nbr variable to hold the result of subtracting the nbr_before raster \n",
    "# from the nbr_after raster.\n",
    "change_in_nbr = nbr_after - nbr_before "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Run the cell below to display the difference raster in a new map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a map.\n",
    "map4 = gis.map()\n",
    "\n",
    "# Add the change_in_nbr value to the map.\n",
    "map4.content.add(change_in_nbr)\n",
    "\n",
    "# Set the map extent to the AOI.\n",
    "map4.content.extent = dict(wild_fires_aoi.envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the map.\n",
    "map4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fire locations now clearly appear in black, contrasting strongly against their light gray surroundings. \n",
    "\n",
    "You'll apply a colorful color ramp to better highlight the burn scars. You'll use the [stretch](https://developers.arcgis.com/python/api-reference/arcgis.raster.functions.html#stretch) function, which allows you to choose among several imagery rendering options, including different stretch types, color ramps, and application of DRA.    \n",
    "\n",
    "24. Run the cell below to change the rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to hold the result of applying a Standard Deviation stretch with DRA\n",
    "# and a Red to Green color ramp to the difference raster.\n",
    "rendered_change_in_nbr = stretch(change_in_nbr, \n",
    "                      stretch_type = \"StdDev\", \n",
    "                      num_stddev=2,\n",
    "                      dra = True,\n",
    "                      colorramp = \"Red to Green\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Run the cell below to display the newly symbolized raster in a new map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a map.\n",
    "map5 = gis.map()\n",
    "\n",
    "# Add the layer to the map.\n",
    "map5.content.add(rendered_change_in_nbr)\n",
    "\n",
    "# Set the extent of the map.\n",
    "map5.content.extent = dict(wild_fires_aoi.envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the map.\n",
    "map5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two burn scars now appear in bright red and are very clearly defined,  contrasting strongly against the lime green surroundings. \n",
    "\n",
    "**Note:** Some small red patches appear in other areas of the image. By examining the previous maps, you can see that, for instance, there are snowy crests (on the left) that had more snow in summer 2014 than in summer 2015. So, some of these pixels went from snow covered to bare earth and also experienced a drop in NBR value. Some other red specks may have been caused by small variations in tree health or activities such as logging. This highlights how important it is to take into account your understanding of the situation on the ground when interpreting the results of imagery analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a class=\"anchor\" id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you used the ArcGIS API for Python and Landsat imagery to determine the extent of two wildfires. You first looked at the imagery through different spectral band combinations to visually assess the fire locations. Then, you calculated the NBR index to specifically highlight burned areas, and identified the burn scars. In a real-world scenario, the Montana Forestry department could then use the analysis results for vegetation succession studies or to plan for future fires in the area.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch goal: Create your own AOI polygon <a class=\"anchor\" id=\"stretch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create your own AOI polygon to select Landsat scenes anywhere in the world. In this optional section, you'll learn how to do this interactively. Search the Living Atlas for an interesting AOI, then attempt to filter the landsat imagery to your selected AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: This output can now be reused as an AOI in any workflow. Just copy and paste these few lines into a notebook cell where you want to set up an AOI polygon, as you did at the beginning of this notebook. Assuming you want to put the polygon in a variable named `my_aoi`, add `my_aoi = (` at the beginning, and add a closing parenthesis `)` at the end. It should match the example below. \n",
    "\n",
    "`my_aoi = Polygon({'spatialReference': {'latestWkid': 3857, 'wkid': 102100},\n",
    " 'rings': [[[359132.9094171927, 6049837.6174895335],\n",
    "   [359573.1851138971, 6046829.05600958],\n",
    "   [358130.0536466472, 6045116.867042529],\n",
    "   [355145.9537419225, 6045214.706345427],\n",
    "   [354020.80059225933, 6047929.74875035],\n",
    "   [355806.3707859886, 6050082.215746779],\n",
    "   [359132.9094171927, 6049837.6174895335]]]})`\n",
    "   \n",
    "Then run the cell and use the polygon to select specific Landsat scenes.\n",
    "\n",
    "You can find other notebooks like this one in the [Analyze imagery with ArcGIS Notebooks](https://learn.arcgis.com/en/paths/analyze-imagery-with-arcgis-notebooks/) learning path. For more information about remote sensing in ArcGIS, see also the [Introduction to Imagery and Remote Sensing](https://introduction-to-remote-sensing-learngis.hub.arcgis.com/) curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments <a class=\"anchor\" id=\"acknowledgments\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Delphine Khanna, principal product engineer at Esri.\n",
    "\n",
    "Thank you to professor Karen Schuckman, Pennsylvania State University, for her invaluable help. \n",
    "\n",
    "If you experience any issues with this notebook, please contact <LearnArcGISSupport@esri.com>."
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Advanced",
   "notebookRuntimeVersion": "6.0"
  },
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
